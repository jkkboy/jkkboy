[ Lab 05 Logistic Classification(Regression) - Eager Execution ]

x_train = [[1., 2.],              # 학습을 위한 x데이터, y데이터 입력
          [2., 3.],
          [3., 1.],
          [4., 3.],
          [5., 3.],
          [6., 2.]]
y_train = [[0.],
          [0.],
          [0.],
          [1.],
          [1.],
          [1.]]

x_test = [[5.,2.]]                # 학습 테스트
y_test = [[1.]]

dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()      # 데이터 셋 = X값과 y값을 실제 x길이 만큼 batch로 학습한 데이터 

W = tf.Variable(tf.zeros([2,1]), name='weight')                 # x 값 (1행 2열)을 연산하기 위해 변수 (2행 1열) 입력  [1, 2] * [2, 1]
b = tf.Variable(tf.zeros([1]), name='bias') 



def logistic_regression(features):
    hypothesis  = tf.div(1., 1. + tf.exp(tf.matmul(features, W) + b))               # w * x + b 함수의 값을 시그모이드 함수로 가설 설정
    return hypothesis

def loss_fn(hypothesis, features, labels):
    cost = -tf.reduce_mean(labels * tf.log(logistic_regression(features)) + (1 - labels) * tf.log(1 - hypothesis))
    return cost                                                                     # 위에 세운 가설의 cost값을 구함

def grad(hypothesis, features, labels):
    with tf.GradientTape() as tape:
        loss_value = loss_fn(logistic_regression(features),features,labels)         # 가설과 실제 값의 loss 값을 구하고
    return tape.gradient(loss_value, [W,b])                                         # gradient로 값을 계속 변화시킴
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)                   # 학습률 계산



for step in range(EPOCHS):                                                          # EPOCHS 만큼 실행
    for features, labels  in tfe.Iterator(dataset):                                 # dataset을 가져와서 x,y에 대입
        grads = grad(logistic_regression(features), features, labels)               # 위에 나온 값의 gradient를 구함
        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))                  # gradient minimize
        if step % 100 == 0:                                                         # 100번 마다 출력
            print("Iter: {}, Loss: {:.4f}".format(step, loss_fn(logistic_regression(features),features,labels)))


def accuracy_fn(hypothesis, labels):                                                # 가설과 함수를 비교
    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)                                   # 구한 가설이 시그모이드에서 0.5보다 큰지 예측
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))           # 실제와 예측값을 비교해서 정확도 출력
    return accuracy



test_acc = accuracy_fn(logistic_regression(x_test),y_test)                          # accuracy 테스트 출력
print("Testset Accuracy: {:.4f}".format(test_acc))

